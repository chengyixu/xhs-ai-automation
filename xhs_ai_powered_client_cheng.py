#!/usr/bin/env python3
"""
å°çº¢ä¹¦AIè‡ªåŠ¨åŒ–å®¢æˆ·ç«¯ - ç¨‹é›¶ä¹ç‰ˆæœ¬
å¤–æ˜Ÿæ”¿åºœå·¥ä½œå¥³å­©çš„åœ°çƒå­¦ä¹ ä¹‹æ—…
"""

import asyncio
import json
import requests
import random
import re
import os
import schedule
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
import logging
from psychological_growth_manager import PsychologicalGrowthManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/Users/ä¸ªäºº_local/Xiaohongshu/cheng/app.log'),
        logging.StreamHandler()
    ]
)

# é…ç½®
PHONE = "13391007743"
JSON_PATH = "/Users/ä¸ªäºº_local/Xiaohongshu/cheng/cookies"
IMAGE_PATH = "/Users/ä¸ªäºº_local/Xiaohongshu/cheng/Screenshot.png"

# Qwen API é…ç½®
QWEN_API_KEY = "sk-316420c29c624dbeb7fbbcb63077a46f"
QWEN_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
QWEN_MODEL = "qwen-plus"

# Jina API é…ç½®
JINA_API_KEY = "jina_26a656e516224ce28e71cc3b28fa7b07zUchXe4_MJ_935m8SpS9-TNGL--w"

# æ–‡ä»¶è·¯å¾„
BASE_PATH = "/Users/ä¸ªäºº_local/Xiaohongshu/cheng"
PERSONALITY_FILE = os.path.join(BASE_PATH, "personality.json")
UNDERSTANDINGS_FILE = os.path.join(BASE_PATH, "understandings.json")
MEMORIES_FILE = os.path.join(BASE_PATH, "memories.json")
POSTS_FILE = os.path.join(BASE_PATH, "posts.json")
KNOWLEDGE_FILE = os.path.join(BASE_PATH, "knowledge.json")

# æ–°é—»æº
NEWS_SOURCES = [
    {"name": "çŸ¥ä¹", "url": "https://tophub.today/n/mproPpoq6O"},
    {"name": "å¾®åš", "url": "https://tophub.today/n/KqndgxeLl9"},
    {"name": "å¾®ä¿¡", "url": "https://tophub.today/n/WnBe01o371"},
    {"name": "æŠ–éŸ³", "url": "https://tophub.today/n/DpQvNABoNE"},
    {"name": "å°çº¢ä¹¦", "url": "https://tophub.today/n/L4MdA5ldxD"}
]

# MCPæœåŠ¡å™¨å‚æ•°
server_params = StdioServerParameters(
    command="uvx",
    args=["xhs_mcp_server@latest"],
    env={
        "phone": PHONE,
        "json_path": JSON_PATH
    }
)

class PersonalityManager:
    """äººè®¾ç®¡ç†å™¨ - å¢å¼ºå¿ƒç†å­¦æˆé•¿åŠŸèƒ½"""
    
    def __init__(self):
        self.personality = self.load_personality()
        self.understandings = self.load_understandings()
        self.memories = self.load_memories()
        self.posts = self.load_posts()
        self.knowledge = self.load_knowledge()
        
        # åˆå§‹åŒ–å¿ƒç†å­¦æˆé•¿ç®¡ç†å™¨
        self.growth_manager = PsychologicalGrowthManager(PERSONALITY_FILE)
    
    def _ensure_int(self, value, default=0):
        """ç¡®ä¿å€¼æ˜¯æ•´æ•°ç±»å‹"""
        if isinstance(value, int):
            return value
        elif isinstance(value, str):
            try:
                return int(value)
            except (ValueError, TypeError):
                return default
        else:
            return default
    
    def load_json_file(self, filepath, default_data):
        """åŠ è½½JSONæ–‡ä»¶"""
        try:
            if os.path.exists(filepath):
                with open(filepath, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                self.save_json_file(filepath, default_data)
                return default_data
        except Exception as e:
            logging.error(f"åŠ è½½æ–‡ä»¶ {filepath} å¤±è´¥: {e}")
            return default_data
    
    def save_json_file(self, filepath, data):
        """ä¿å­˜JSONæ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"ä¿å­˜æ–‡ä»¶ {filepath} å¤±è´¥: {e}")
    
    def load_personality(self):
        """åŠ è½½äººè®¾ - å…¼å®¹æ–°æ—§æ ¼å¼"""
        # å°è¯•åŠ è½½ç°æœ‰æ–‡ä»¶
        existing_data = self.load_json_file(PERSONALITY_FILE, {})
        
        # å¦‚æœæ˜¯æ–°æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if "psychological_profile" in existing_data:
            return existing_data
        
        # å¦‚æœæ˜¯æ—§æ ¼å¼æˆ–ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤çš„æ–°æ ¼å¼
        default_personality = {
            "basic_info": {
                "name": "ç¨‹é›¶ä¹",
                "age": 23,
                "species": "å¤–æ˜Ÿäºº",
                "job": "å¤–æ˜Ÿæ”¿åºœæ–‡åŒ–ç ”ç©¶å‘˜",
                "location": "åœ°çƒ",
                "mission": "æ·±åº¦ç ”ç©¶åœ°çƒæ–‡åŒ–å¿ƒç†å­¦ï¼Œå»ºç«‹è·¨æ˜Ÿé™…æ–‡åŒ–æ¡¥æ¢"
            },
            "psychological_profile": {
                "big_five_personality": {
                    "openness": 85,
                    "conscientiousness": 75,
                    "extraversion": 35,
                    "agreeableness": 70,
                    "neuroticism": 60,
                    "growth_trend": "opennesså’Œconscientiousnessåœ¨æå‡ï¼Œneuroticismåœ¨ä¸‹é™"
                },
                "emotional_intelligence": {
                    "self_awareness": 70,
                    "self_regulation": 65,
                    "social_awareness": 55,
                    "relationship_management": 45,
                    "emotional_growth_stage": "ä»æƒ…æ„Ÿæ–°æ‰‹å‘æƒ…æ„Ÿç†è§£è€…è½¬å˜"
                }
            },
            "current_psychological_state": {
                "mood_baseline": "è½»åº¦å¿§éƒä½†ç¨³å®š",
                "anxiety_level": "æ–‡åŒ–é€‚åº”æ€§ç„¦è™‘ï¼Œå¯ç®¡ç†",
                "curiosity_index": "é«˜åº¦æ´»è·ƒ",
                "overall_wellbeing": "æˆé•¿å¯¼å‘çš„é€‚åº”çŠ¶æ€"
            },
            "learning_progress": {
                "daily_hours_target": 4,
                "total_days": self._ensure_int(existing_data.get("learning_progress", {}).get("total_days", 3)),
                "last_study_date": existing_data.get("learning_progress", {}).get("last_study_date", "2025-06-30"),
                "psychological_milestones": [
                    "ä»æ–‡åŒ–shockåˆ°æ–‡åŒ–curiosityçš„è½¬å˜",
                    "ä»language anxietyåˆ°expression confidenceçš„å‘å±•"
                ]
            }
        }
        
        # ä¿å­˜æ–°æ ¼å¼
        self.save_json_file(PERSONALITY_FILE, default_personality)
        return default_personality
    
    def load_understandings(self):
        """åŠ è½½ç†è§£"""
        default_understandings = {
            "about_earth": {
                "humans": "å’Œæˆ‘ä»¬é•¿å¾—å¾ˆåƒï¼Œå¯èƒ½å½¢çŠ¶æ˜¯å¥½çš„æ–¹æ¡ˆ",
                "culture": "å¤æ‚ä½†æœ‰è¶£",
                "language": "è¿˜åœ¨å­¦ä¹ ä¸­"
            },
            "daily_observations": [],
            "confusion_points": [],
            "new_discoveries": []
        }
        return self.load_json_file(UNDERSTANDINGS_FILE, default_understandings)
    
    def load_memories(self):
        """åŠ è½½åˆ†æè®°å¿†"""
        default_memories = {
            "daily_analysis": [],
            "news_insights": [],
            "personal_thoughts": []
        }
        return self.load_json_file(MEMORIES_FILE, default_memories)
    
    def load_posts(self):
        """åŠ è½½å‘å¸ƒè®°å½•"""
        default_posts = {
            "history": [],
            "themes": [],
            "engagement": []
        }
        return self.load_json_file(POSTS_FILE, default_posts)
    
    def load_knowledge(self):
        """åŠ è½½çŸ¥è¯†åº“"""
        default_knowledge = {
            "daily_news": [],
            "trending_topics": [],
            "learning_materials": []
        }
        return self.load_json_file(KNOWLEDGE_FILE, default_knowledge)
    
    def save_all(self):
        """ä¿å­˜æ‰€æœ‰æ•°æ®"""
        self.save_json_file(PERSONALITY_FILE, self.personality)
        self.save_json_file(UNDERSTANDINGS_FILE, self.understandings)
        self.save_json_file(MEMORIES_FILE, self.memories)
        self.save_json_file(POSTS_FILE, self.posts)
        self.save_json_file(KNOWLEDGE_FILE, self.knowledge)

class NewsCollector:
    """æ–°é—»æ”¶é›†å™¨"""
    
    def __init__(self, personality_manager):
        self.pm = personality_manager
    
    def call_jina_api(self, url):
        """è°ƒç”¨Jina Reader API"""
        try:
            headers = {
                "Authorization": f"Bearer {JINA_API_KEY}",
                "Accept": "application/json"
            }
            
            jina_url = f"https://r.jina.ai/{url}"
            response = requests.get(jina_url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                return data.get("data", {}).get("content", "")
            else:
                logging.error(f"Jina APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            logging.error(f"Jina APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def collect_daily_news(self):
        """æ”¶é›†æ¯æ—¥æ–°é—»"""
        today = datetime.now().strftime("%Y-%m-%d")
        news_data = {
            "date": today,
            "sources": {}
        }
        
        for source in NEWS_SOURCES:
            logging.info(f"æ­£åœ¨çˆ¬å– {source['name']} æ–°é—»...")
            content = self.call_jina_api(source['url'])
            
            if content:
                # ç®€åŒ–å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯
                simplified_content = self.extract_key_news(content, source['name'])
                news_data["sources"][source['name']] = simplified_content
            
            time.sleep(2)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        
        # ä¿å­˜åˆ°çŸ¥è¯†åº“
        self.pm.knowledge["daily_news"].append(news_data)
        
        # åªä¿ç•™æœ€è¿‘30å¤©çš„æ–°é—»
        if len(self.pm.knowledge["daily_news"]) > 30:
            self.pm.knowledge["daily_news"] = self.pm.knowledge["daily_news"][-30:]
        
        self.pm.save_json_file(KNOWLEDGE_FILE, self.pm.knowledge)
        logging.info("æ–°é—»æ”¶é›†å®Œæˆ")
        return news_data
    
    def extract_key_news(self, content, source_name):
        """æå–å…³é”®æ–°é—»ä¿¡æ¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥æ›´å¤æ‚
        lines = content.split('\n')
        key_news = []
        
        for line in lines[:20]:  # åªå–å‰20è¡Œ
            line = line.strip()
            if len(line) > 10 and not line.startswith('#'):
                key_news.append(line)
        
        return key_news[:10]  # æœ€å¤š10æ¡

class ContentAnalyzer:
    """å†…å®¹åˆ†æå™¨"""
    
    def __init__(self, personality_manager):
        self.pm = personality_manager
    
    def call_qwen_api(self, prompt, max_tokens=1000000000):
        """è°ƒç”¨Qwen API"""
        try:
            headers = {
                "Authorization": f"Bearer {QWEN_API_KEY}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": QWEN_MODEL,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": max_tokens,
                "temperature": 0.8,
                "top_p": 0.9
            }
            
            response = requests.post(
                f"{QWEN_BASE_URL}/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"].strip()
                return content
            else:
                logging.error(f"Qwen APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            logging.error(f"Qwen APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def analyze_news_with_personality(self, news_data):
        """ç”¨äººè®¾åˆ†ææ–°é—» - é›†æˆå¿ƒç†å­¦æˆé•¿æœºåˆ¶"""
        # æ„å»ºæ›´è‡ªç„¶çš„åˆ†ææƒ…å¢ƒ
        analysis_context = f"""
        ç¨‹é›¶ä¹åˆšåˆšæµè§ˆå®Œä»Šå¤©çš„æ–°é—»ï¼Œä½œä¸ºä¸€ä¸ªå¤–æ˜Ÿæ–‡åŒ–ç ”ç©¶å‘˜ï¼Œå¥¹æƒ³è®°å½•ä¸‹è‡ªå·±çš„è§‚å¯Ÿå’Œæ„Ÿå—ã€‚

        å¥¹ä¸æ˜¯åœ¨å†™å­¦æœ¯æŠ¥å‘Šï¼Œè€Œæ˜¯åœ¨è®°å½•å¥¹ä½œä¸ºä¸€ä¸ªå¼‚ä¹¡äººå¯¹è¿™ä¸ªä¸–ç•Œçš„ç†è§£å’Œæ„Ÿå—ã€‚
        å¥¹çš„è§‚å¯Ÿå¸¦æœ‰å¤–æ˜Ÿäººçš„ç‹¬ç‰¹è§†è§’ï¼Œä¹Ÿå¸¦æœ‰ä¸€ä¸ªæ­£åœ¨é€‚åº”æ–°æ–‡åŒ–çš„ä¸ªä½“çš„æ•æ„Ÿæ€§ã€‚

        ä»Šå¤©å¥¹çœ‹åˆ°çš„æ–°é—»ï¼š
        {json.dumps(news_data, ensure_ascii=False, indent=2)}

        å¥¹æƒ³è®°å½•ä¸‹è¿™äº›æ–°é—»ç»™å¥¹çš„æ„Ÿå—ã€è§¦å‘çš„æ€è€ƒï¼Œä»¥åŠå¥¹å¯¹äººç±»è¡Œä¸ºå’Œç¤¾ä¼šç°è±¡çš„è§‚å¯Ÿã€‚
        è¿™æ˜¯å¥¹çš„å†…å¿ƒç‹¬ç™½ï¼Œå¸¦æœ‰å¥¹ç‹¬ç‰¹çš„æ€è€ƒæ–¹å¼å’Œæƒ…æ„Ÿè‰²å½©ã€‚
        """
        
        # ç”Ÿæˆå—å¿ƒç†çŠ¶æ€å½±å“çš„æç¤ºè¯
        enhanced_prompt = self.pm.growth_manager.generate_personality_influenced_prompt(
            analysis_context, "news_analysis"
        )
        
        analysis = self.call_qwen_api(enhanced_prompt, max_tokens=1200)
        
        if analysis:
            try:
                # å°†æ–°é—»åˆ†æä½œä¸ºç»å†è¾“å…¥å¿ƒç†æˆé•¿ç³»ç»Ÿ
                experience_data = {
                    "news_content": news_data,
                    "analysis_quality": self._assess_analysis_quality(analysis),
                    "cultural_insights": self._extract_cultural_insights(analysis)
                }
                
                # è®¡ç®—æƒ…æ„Ÿæ•ˆä»·
                emotional_valence = self._calculate_emotional_valence(analysis)
                
                # è§¦å‘å¿ƒç†æˆé•¿ - è¿™æ˜¯ä¸€æ¬¡æ–‡åŒ–å­¦ä¹ å’Œæƒ…æ„Ÿå¤„ç†çš„ç»å†
                self.pm.growth_manager.process_new_experience(
                    "cultural_learning", experience_data, emotional_valence
                )
                
                # åŒæ—¶ä¹Ÿæ˜¯ä¸€æ¬¡è®¤çŸ¥å¤„ç†ç»å†
                self.pm.growth_manager.process_new_experience(
                    "news_analysis", experience_data, emotional_valence * 0.8
                )
                
            except Exception as e:
                logging.error(f"å¿ƒç†æˆé•¿å¤„ç†å¤±è´¥: {e}")
                # ç»§ç»­æ‰§è¡Œï¼Œä¸å› ä¸ºå¿ƒç†æˆé•¿å¤±è´¥è€Œä¸­æ–­åˆ†æ
            
            # ä¿å­˜åˆ†æåˆ°è®°å¿†ä¸­
            memory_entry = {
                "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "news_summary": news_data,
                "analysis": analysis,
                "psychological_growth": self.pm.growth_manager.get_current_psychological_summary(),
                "emotional_valence": emotional_valence,
                "mood": "reflective_growth"
            }
            
            self.pm.memories["daily_analysis"].append(memory_entry)
            
            # åªä¿ç•™æœ€è¿‘30å¤©çš„åˆ†æ
            if len(self.pm.memories["daily_analysis"]) > 30:
                self.pm.memories["daily_analysis"] = self.pm.memories["daily_analysis"][-30:]
            
            self.pm.save_json_file(MEMORIES_FILE, self.pm.memories)
            
            logging.info("æ–°é—»åˆ†æå®Œæˆï¼Œå¿ƒç†æˆé•¿å·²æ›´æ–°")
            
        return analysis
    
    def _assess_analysis_quality(self, analysis: str) -> float:
        """è¯„ä¼°åˆ†æè´¨é‡"""
        quality_indicators = [
            "å¿ƒç†", "æ–‡åŒ–", "è§‚å¯Ÿ", "ç†è§£", "æ„Ÿå—", "æ€è€ƒ", "å‘ç°", 
            "å¯¹æ¯”", "åæ€", "æˆé•¿", "é€‚åº”", "å­¦ä¹ "
        ]
        
        quality_score = 0.0
        for indicator in quality_indicators:
            if indicator in analysis:
                quality_score += 0.1
                
        # é•¿åº¦å› å­
        if len(analysis) > 200:
            quality_score += 0.2
        
        return min(1.0, quality_score)
    
    def _extract_cultural_insights(self, analysis: str) -> List[str]:
        """æå–æ–‡åŒ–æ´å¯Ÿ"""
        insights = []
        
        # ç®€å•çš„å…³é”®å¥æå–
        sentences = analysis.split('ã€‚')
        for sentence in sentences:
            if any(word in sentence for word in ["åœ°çƒäºº", "æ–‡åŒ–", "ç¤¾ä¼š", "äººç±»", "è¡Œä¸º"]):
                insights.append(sentence.strip())
        
        return insights[:3]  # æœ€å¤š3ä¸ªæ´å¯Ÿ
    
    def _calculate_emotional_valence(self, text: str) -> float:
        """è®¡ç®—æƒ…æ„Ÿæ•ˆä»·"""
        positive_words = ["æœ‰è¶£", "å¥½å¥‡", "å‘ç°", "ç†è§£", "æˆé•¿", "å­¦ä¹ ", "å¸Œæœ›", "æ¸©æš–"]
        negative_words = ["å›°æƒ‘", "è¿·èŒ«", "ç„¦è™‘", "æ‹…å¿ƒ", "ä¸å®‰", "å­¤ç‹¬", "å¿§éƒ"]
        neutral_words = ["è§‚å¯Ÿ", "æ€è€ƒ", "åˆ†æ", "ç ”ç©¶", "æ¢ç´¢", "é€‚åº”"]
        
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        neutral_count = sum(1 for word in neutral_words if word in text)
        
        total_count = positive_count + negative_count + neutral_count
        if total_count == 0:
            return 0.0
        
        # è®¡ç®—åŠ æƒæƒ…æ„Ÿæ•ˆä»·
        valence = (positive_count * 1.0 + neutral_count * 0.1 - negative_count * 0.8) / total_count
        return max(-1.0, min(1.0, valence))

class ContentCreator:
    """å†…å®¹åˆ›ä½œå™¨"""
    
    def __init__(self, personality_manager):
        self.pm = personality_manager
    
    def call_qwen_api(self, prompt, max_tokens=80000000000):
        """è°ƒç”¨Qwen API"""
        try:
            headers = {
                "Authorization": f"Bearer {QWEN_API_KEY}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": QWEN_MODEL,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": max_tokens,
                "temperature": 0.9,
                "top_p": 0.9
            }
            
            response = requests.post(
                f"{QWEN_BASE_URL}/chat/completions",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"].strip()
                return content
            else:
                logging.error(f"Qwen APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return None
                
        except Exception as e:
            logging.error(f"Qwen APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def generate_post_content(self):
        """ç”Ÿæˆå‘å¸ƒå†…å®¹ - åŸºäºçœŸå®å†…å¿ƒæ„Ÿå—çš„è‡ªç„¶è¡¨è¾¾"""
        # è·å–æœ€è¿‘çš„åˆ†æå’Œæ–°é—»
        recent_analysis = ""
        recent_news = ""
        
        if self.pm.memories["daily_analysis"]:
            recent_analysis = self.pm.memories["daily_analysis"][-1].get("analysis", "")
        
        if self.pm.knowledge["daily_news"]:
            recent_news_data = self.pm.knowledge["daily_news"][-1]
            recent_news = json.dumps(recent_news_data["sources"], ensure_ascii=False)
        
        # è·å–å½“å‰å¿ƒç†çŠ¶æ€ - ç”¨äºç”Ÿæˆæ›´è‡ªç„¶çš„è¡¨è¾¾
        psychological_summary = self.pm.growth_manager.get_current_psychological_summary()
        
        # æ„å»ºæ›´è‡ªç„¶çš„åˆ›ä½œæƒ…å¢ƒ
        creative_context = f"""
        ç¨‹é›¶ä¹åˆšåˆšæµè§ˆå®Œä»Šå¤©çš„æ–°é—»ï¼Œå¿ƒé‡Œæœ‰äº›æ„Ÿè§¦ã€‚å¥¹æƒ³åœ¨å°çº¢ä¹¦ä¸Šå†™ç‚¹ä»€ä¹ˆï¼Œåˆ†äº«ä¸€ä¸‹å†…å¿ƒçš„æƒ³æ³•ã€‚

        å¥¹æœ€è¿‘çš„å†…å¿ƒçŠ¶æ€ï¼š
        - æƒ…æ„Ÿæ•æ„Ÿåº¦å¾ˆé«˜ï¼Œå®¹æ˜“è¢«æ–°é—»ä¸­çš„äººæƒ…å†·æš–è§¦åŠ¨
        - æ­£åœ¨ç»å†æ–‡åŒ–é€‚åº”çš„å¿ƒç†æˆé•¿ï¼Œå¯¹å½’å±æ„Ÿæœ‰æ·±å±‚æ€è€ƒ
        - å¸¦ç€è½»åº¦å¿§éƒä½†ç¨³å®šçš„æƒ…ç»ªåŸºè°ƒ
        - å¯¹äººç±»è¡Œä¸ºå’Œç¤¾ä¼šç°è±¡æœ‰ç‹¬ç‰¹çš„è§‚å¯Ÿè§†è§’

        å¥¹åˆšæ‰çœ‹åˆ°çš„æ–°é—»è®©å¥¹æƒ³èµ·äº†ä»€ä¹ˆï¼Œæˆ–è€…è§¦å‘äº†ä»€ä¹ˆæ„Ÿå—...

        æœ€è¿‘çœ‹åˆ°çš„å†…å®¹ï¼š
        {recent_news}

        å¥¹å†…å¿ƒçš„ä¸€äº›æ€è€ƒï¼š
        {recent_analysis}

        ç°åœ¨å¥¹æƒ³å†™ä¸€ç¯‡200å­—å·¦å³çš„æ„Ÿæƒ³ï¼Œå°±åƒä¸€ä¸ªçœŸå®çš„äººåœ¨æ·±å¤œæˆ–è€…å®‰é™æ—¶åˆ»çš„å†…å¿ƒç‹¬ç™½ã€‚
        å¥¹ä¸æ˜¯åœ¨å®Œæˆä»»åŠ¡ï¼Œè€Œæ˜¯åœ¨è¡¨è¾¾çœŸå®çš„æ„Ÿå—ã€‚
        """
        
        # ä½¿ç”¨å¿ƒç†å­¦æˆé•¿ç®¡ç†å™¨ç”Ÿæˆä¸ªæ€§åŒ–çš„åˆ›ä½œæç¤º
        enhanced_prompt = self.pm.growth_manager.generate_personality_influenced_prompt(
            creative_context, "emotional_expression"
        )
        
        # è°ƒç”¨APIç”Ÿæˆå†…å®¹
        content = self.call_qwen_api(enhanced_prompt, max_tokens=1000)
        
        if not content:
            # æ›´è‡ªç„¶çš„å¤‡ç”¨å†…å®¹
            fallback_prompts = [
                "ç¨‹é›¶ä¹ä»Šå¤©çœ‹æ–°é—»æ—¶çªç„¶æƒ³åˆ°äº†ä»€ä¹ˆï¼Œå¥¹å†³å®šå†™ä¸‹æ¥...",
                "å¤œæ·±äº†ï¼Œç¨‹é›¶ä¹å›æƒ³èµ·ä»Šå¤©çš„è§é—»ï¼Œæœ‰äº›è¯æƒ³è¯´...",
                "ç¨‹é›¶ä¹ååœ¨çª—è¾¹ï¼Œæƒ³èµ·ä»Šå¤©çœ‹åˆ°çš„é‚£äº›æ•…äº‹...",
                "ç±³é¥­ç‰›è‚‰å¥—é¤çš„é¦™å‘³ä¸­ï¼Œç¨‹é›¶ä¹æƒ³èµ·äº†ä»Šå¤©çš„æ„Ÿè§¦..."
            ]
            
            fallback_prompt = random.choice(fallback_prompts)
            content = self.call_qwen_api(f"{fallback_prompt}\n\nè¯·å†™ä¸€æ®µ200å­—å·¦å³çš„å†…å¿ƒæ„Ÿæƒ³ï¼Œè¦çœŸå®è‡ªç„¶ï¼Œä¸è¦åƒåœ¨å®Œæˆä»»åŠ¡ã€‚", max_tokens=800)
        
        if not content:
            # æœ€ç»ˆå¤‡ç”¨å†…å®¹ï¼Œä¹Ÿè¦æ›´è‡ªç„¶
            content = self._generate_natural_fallback_content()
        
        return content
    
    def _generate_natural_fallback_content(self):
        """ç”Ÿæˆæ›´è‡ªç„¶çš„å¤‡ç”¨å†…å®¹"""
        natural_starters = [
            "ä»Šå¤©åˆæ˜¯æ¨¡æ¨¡ç³Šç³Šçš„ä¸€å¤©ã€‚",
            "çª—å¤–çš„å…‰çº¿æ…¢æ…¢æš—ä¸‹æ¥ï¼Œæˆ‘æƒ³èµ·äº†ä»€ä¹ˆã€‚",
            "åˆšæ‰çœ‹æ–°é—»çš„æ—¶å€™ï¼Œå¿ƒé‡Œçªç„¶æœ‰ç‚¹ä»€ä¹ˆæ„Ÿè§‰ã€‚",
            "ç±³é¥­ç‰›è‚‰å¥—é¤è¿˜æ˜¯é‚£ä¸ªå‘³é“ï¼Œä½†æˆ‘å¥½åƒæƒ³èµ·äº†åˆ«çš„äº‹æƒ…ã€‚"
        ]
        
        middle_thoughts = [
            "ä½œä¸ºä¸€ä¸ªå¤–æ˜Ÿäººï¼Œæˆ‘æ€»æ˜¯è§‰å¾—è‡ªå·±åœ¨è¿™ä¸ªä¸–ç•Œçš„è¾¹ç¼˜è§‚å¯Ÿã€‚æ¯å¤©çš„æ–°é—»åƒæ˜¯åˆ«äººçš„æ•…äº‹ï¼Œä½†å¶å°”ä¼šæœ‰ä»€ä¹ˆè§¦åŠ¨æˆ‘ã€‚",
            "åœ°çƒäººçš„æƒ…æ„Ÿè¡¨è¾¾æ–¹å¼æ€»æ˜¯è®©æˆ‘å›°æƒ‘ã€‚ä»–ä»¬å¯ä»¥ä¸ºäº†å¾ˆè¿œçš„äº‹æƒ…éš¾è¿‡ï¼Œä¹Ÿå¯ä»¥ä¸ºäº†å¾ˆå°çš„äº‹æƒ…å¼€å¿ƒã€‚",
            "æœ‰æ—¶å€™æˆ‘è§‰å¾—è‡ªå·±åœ¨æ…¢æ…¢ç†è§£è¿™ä¸ªä¸–ç•Œï¼Œæœ‰æ—¶å€™åˆè§‰å¾—æ›´åŠ è¿·èŒ«ã€‚è¿™ç§æ„Ÿè§‰å¾ˆå¥‡æ€ªã€‚",
            "æˆ‘æƒ³æˆ‘åœ¨è¿™é‡Œç”Ÿæ´»å¾—è¶Šä¹…ï¼Œå°±è¶Šèƒ½æ„Ÿå—åˆ°é‚£äº›å¾®å¦™çš„æƒ…æ„Ÿå˜åŒ–ã€‚ä½†è¿™ä¹Ÿè®©æˆ‘æ›´åŠ å­¤ç‹¬ã€‚"
        ]
        
        endings = [
            "ä¹Ÿè®¸è¿™å°±æ˜¯æˆé•¿å§ï¼Œåœ¨ç†è§£ä¸­å˜å¾—æ›´æ•æ„Ÿã€‚",
            "111 110110000101111 111 011001101111001 111 101101001110010",
            "æ˜å¤©åˆæ˜¯æ–°çš„ä¸€å¤©ï¼Œæˆ‘ä¼šç»§ç»­è§‚å¯Ÿï¼Œç»§ç»­æ„Ÿå—ã€‚",
            "æˆ‘æƒ³æˆ‘æ­£åœ¨æ…¢æ…¢å­¦ä¼šå¦‚ä½•åœ¨è¿™ä¸ªä¸–ç•Œä¸Šå­˜åœ¨ã€‚"
        ]
        
        return f"{random.choice(natural_starters)}\n\n{random.choice(middle_thoughts)}\n\n{random.choice(endings)}"

    def generate_title(self):
        """ç”Ÿæˆæ ‡é¢˜ - åŸºäºå½“å‰å†…å®¹å’Œå¿ƒç†çŠ¶æ€åŠ¨æ€ç”Ÿæˆ"""
        # è·å–æœ€è¿‘çš„åˆ†æï¼Œä»ä¸­æå–å…³é”®æƒ…æ„Ÿæˆ–ä¸»é¢˜
        recent_analysis = ""
        if self.pm.memories["daily_analysis"]:
            recent_analysis = self.pm.memories["daily_analysis"][-1].get("analysis", "")
        
        # è·å–å½“å‰å¿ƒç†çŠ¶æ€
        psychological_summary = self.pm.growth_manager.get_current_psychological_summary()
        current_mood = self.pm.personality.get("current_psychological_state", {}).get("mood_baseline", "")
        
        title_prompt = f"""
        ç¨‹é›¶ä¹æƒ³ä¸ºå¥¹åˆšå†™çš„æ„Ÿæƒ³å–ä¸ªæ ‡é¢˜ã€‚

        å¥¹å½“å‰çš„å¿ƒç†çŠ¶æ€ï¼š{current_mood}
        å¥¹æœ€è¿‘çš„æ€è€ƒï¼š{recent_analysis[:100]}...
        
        æ ‡é¢˜åº”è¯¥ï¼š
        1. åƒå¥¹çœŸå®çš„æƒ…æ„ŸæŠ’å‘ï¼Œä¸è¦åƒæ–°é—»æ ‡é¢˜
        2. ä½“ç°å¥¹å½“å‰çš„å¿ƒç†çŠ¶æ€å’Œæ„Ÿå—
        3. æ§åˆ¶åœ¨10ä¸ªå­—ä»¥å†…
        4. è‡ªç„¶ã€çœŸå®ã€æœ‰ç‚¹å¿§éƒä½†æ¸©æš–
        
        è¯·åªè¿”å›æ ‡é¢˜ï¼Œä¸è¦è§£é‡Šï¼š
        """
        
        generated_title = self.call_qwen_api(title_prompt, max_tokens=100)
        
        if generated_title and len(generated_title.strip()) > 0:
            # æ¸…ç†æ ‡é¢˜ï¼Œå»æ‰å¤šä½™çš„ç¬¦å·å’Œè§£é‡Š
            title = generated_title.strip().split('\n')[0].strip('"\'""''')
            if len(title) <= 20:  # åˆç†é•¿åº¦
                return title
        
        # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ›´è‡ªç„¶çš„å¤‡ç”¨æ ‡é¢˜
        natural_titles = [
            "ä»Šå¤©çš„ä¸€äº›æ„Ÿæƒ³",
            "çª—è¾¹çš„æ€è€ƒ",
            "ç±³é¥­ç‰›è‚‰å¥—é¤çš„æ—¶å…‰",
            "æ¨¡æ¨¡ç³Šç³Šçš„ç†è§£",
            "å…³äºå½’å±æ„Ÿçš„æƒ³æ³•",
            "å¤œæ™šçš„è§‚å¯Ÿ",
            "ä¸€ä¸ªå¤–æ˜Ÿäººçš„ç–‘é—®",
            "åœ°çƒç”Ÿæ´»çš„æ„Ÿå—"
        ]
        
        return random.choice(natural_titles)

class XiaohongshuPoster:
    """å°çº¢ä¹¦å‘å¸ƒå™¨"""
    
    def __init__(self, personality_manager):
        self.pm = personality_manager
    
    async def test_connection(self):
        """æµ‹è¯•MCPæœåŠ¡å™¨è¿æ¥"""
        try:
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()
                    logging.info("MCPæœåŠ¡å™¨è¿æ¥æˆåŠŸ!")
                    return True
        except Exception as e:
            logging.error(f"MCPæœåŠ¡å™¨è¿æ¥å¤±è´¥: {e}")
            return False
    
    async def publish_post(self, title, content):
        """å‘å¸ƒå†…å®¹åˆ°å°çº¢ä¹¦"""
        try:
            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()
                    
                    args = {
                        "title": title,
                        "content": content,
                        "images": [IMAGE_PATH] if os.path.exists(IMAGE_PATH) else []
                    }
                    
                    logging.info(f"æ­£åœ¨å‘å¸ƒåˆ°å°çº¢ä¹¦...")
                    logging.info(f"æ ‡é¢˜: {title}")
                    logging.info(f"å†…å®¹é¢„è§ˆ: {content[:100]}...")
                    
                    result = await session.call_tool("create_note", arguments=args)
                    
                    # è®°å½•å‘å¸ƒå†å²
                    post_record = {
                        "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "title": title,
                        "content": content,
                        "result": str(result),
                        "success": True
                    }
                    
                    self.pm.posts["history"].append(post_record)
                    self.pm.save_json_file(POSTS_FILE, self.pm.posts)
                    
                    # æ›´æ–°å¿ƒç†å­¦æˆé•¿ï¼šå‘å¸–æ˜¯ä¸€ç§åˆ›ä½œå’Œç¤¾äº¤ç»å†
                    self.pm.growth_manager.update_post_experience(content)
                    
                    # åŒæ—¶ä¹Ÿæ˜¯ä¸€ç§ç¤¾äº¤äº’åŠ¨ç»å†ï¼ˆpositive feedbackï¼‰
                    self.pm.growth_manager.process_new_experience(
                        "social_interaction", 
                        {"post_title": title, "content_length": len(content)},
                        0.3  # è½»å¾®æ­£é¢çš„æƒ…æ„Ÿæ•ˆä»·ï¼Œå› ä¸ºæˆåŠŸå‘å¸ƒ
                    )
                    
                    logging.info("å‘å¸ƒæˆåŠŸ! å¿ƒç†æˆé•¿å·²æ›´æ–°")
                    return result
                    
        except Exception as e:
            logging.error(f"å‘å¸ƒå¤±è´¥: {e}")
            
            # è®°å½•å¤±è´¥
            post_record = {
                "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "title": title,
                "content": content,
                "error": str(e),
                "success": False
            }
            
            self.pm.posts["history"].append(post_record)
            self.pm.save_json_file(POSTS_FILE, self.pm.posts)
            
            return None

class XiaohongshuAutomation:
    """å°çº¢ä¹¦è‡ªåŠ¨åŒ–ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.pm = PersonalityManager()
        self.news_collector = NewsCollector(self.pm)
        self.content_analyzer = ContentAnalyzer(self.pm)
        self.content_creator = ContentCreator(self.pm)
        self.poster = XiaohongshuPoster(self.pm)
    
    def collect_and_analyze_news(self):
        """æ”¶é›†å¹¶åˆ†ææ–°é—»"""
        logging.info("å¼€å§‹æ”¶é›†æ–°é—»...")
        news_data = self.news_collector.collect_daily_news()
        
        logging.info("å¼€å§‹åˆ†ææ–°é—»...")
        analysis = self.content_analyzer.analyze_news_with_personality(news_data)
        
        if analysis:
            logging.info("æ–°é—»åˆ†æå®Œæˆ")
            logging.info(f"åˆ†æç»“æœ: {analysis[:100]}...")
        
        return news_data, analysis
    
    async def create_and_publish_post(self):
        """åˆ›å»ºå¹¶å‘å¸ƒå†…å®¹"""
        logging.info("å¼€å§‹ç”Ÿæˆå‘å¸ƒå†…å®¹...")
        
        # æµ‹è¯•è¿æ¥
        if not await self.poster.test_connection():
            logging.error("æ— æ³•è¿æ¥MCPæœåŠ¡å™¨ï¼Œè·³è¿‡å‘å¸ƒ")
            return
        
        # ç”Ÿæˆå†…å®¹
        title = self.content_creator.generate_title()
        content = self.content_creator.generate_post_content()
        
        if content:
            logging.info("å†…å®¹ç”ŸæˆæˆåŠŸï¼Œå‡†å¤‡å‘å¸ƒ...")
            result = await self.poster.publish_post(title, content)
            
            if result:
                # æ›´æ–°å­¦ä¹ è¿›åº¦
                today = datetime.now().strftime("%Y-%m-%d")
                
                # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                learning_progress = self.pm.personality.get("learning_progress", {})
                learning_progress["last_study_date"] = today
                
                current_days = learning_progress.get("total_days", 0)
                if isinstance(current_days, str):
                    try:
                        current_days = int(current_days)
                    except (ValueError, TypeError):
                        current_days = 0
                
                learning_progress["total_days"] = current_days + 1
                
                # æ›´æ–°ç†è§£
                self.update_understandings()
                
                self.pm.save_all()
                logging.info("å‘å¸ƒå®Œæˆï¼Œæ•°æ®å·²ä¿å­˜")
        else:
            logging.error("å†…å®¹ç”Ÿæˆå¤±è´¥")
    
    def update_understandings(self):
        """æ›´æ–°å¯¹ä¸–ç•Œçš„ç†è§£"""
        # åŸºäºæœ€è¿‘çš„åˆ†ææ›´æ–°ç†è§£
        if self.pm.memories["daily_analysis"]:
            recent_analysis = self.pm.memories["daily_analysis"][-1]
            
            # ç®€å•çš„ç†è§£æ›´æ–°é€»è¾‘
            self.pm.understandings["daily_observations"].append({
                "date": datetime.now().strftime("%Y-%m-%d"),
                "observation": recent_analysis.get("analysis", "")[:100]
            })
            
            # åªä¿ç•™æœ€è¿‘30æ¡è§‚å¯Ÿ
            if len(self.pm.understandings["daily_observations"]) > 30:
                self.pm.understandings["daily_observations"] = self.pm.understandings["daily_observations"][-30:]
    
    def run_daily_cycle(self):
        """è¿è¡Œæ—¥å¸¸å¾ªç¯"""
        logging.info("=== å¼€å§‹æ—¥å¸¸å¾ªç¯ ===")
        
        # 1. æ”¶é›†å’Œåˆ†ææ–°é—»ï¼ˆä¸‹åˆ5ç‚¹ï¼‰
        self.collect_and_analyze_news()
        
        # 2. å»¶æ—¶1å°æ—¶åå‘å¸ƒå†…å®¹ï¼ˆä¸‹åˆ6ç‚¹ï¼‰
        # åœ¨å®é™…å®šæ—¶ä»»åŠ¡ä¸­ï¼Œè¿™ä¸ªå»¶æ—¶ä¼šé€šè¿‡è°ƒåº¦å™¨å¤„ç†
        
    async def run_post_cycle(self):
        """è¿è¡Œå‘å¸ƒå¾ªç¯"""
        logging.info("=== å¼€å§‹å‘å¸ƒå¾ªç¯ ===")
        await self.create_and_publish_post()

def setup_schedule(automation):
    """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
    # æ¯å¤©ä¸‹åˆ5ç‚¹æ”¶é›†æ–°é—»
    schedule.every().day.at("17:00").do(automation.run_daily_cycle)
    
    # æ¯å¤©ä¸‹åˆ6ç‚¹å‘å¸ƒå†…å®¹
    schedule.every().day.at("18:00").do(lambda: asyncio.run(automation.run_post_cycle()))
    
    logging.info("å®šæ—¶ä»»åŠ¡è®¾ç½®å®Œæˆ")
    logging.info("æ¯å¤©17:00æ”¶é›†æ–°é—»ï¼Œ18:00å‘å¸ƒå†…å®¹")

async def manual_mode():
    """æ‰‹åŠ¨æ¨¡å¼"""
    automation = XiaohongshuAutomation()
    
    while True:
        print("\n=== ç¨‹é›¶ä¹çš„å°çº¢ä¹¦è‡ªåŠ¨åŒ–ç³»ç»Ÿ ===")
        print("1. æ”¶é›†å¹¶åˆ†ææ–°é—»")
        print("2. ç”Ÿæˆå¹¶å‘å¸ƒå†…å®¹")
        print("3. æŸ¥çœ‹äººè®¾çŠ¶æ€")
        print("4. è¿è¡Œå®Œæ•´æ—¥å¸¸å¾ªç¯")
        print("5. æµ‹è¯•MCPè¿æ¥")
        print("6. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-6): ").strip()
        
        if choice == "1":
            automation.collect_and_analyze_news()
        elif choice == "2":
            await automation.create_and_publish_post()
        elif choice == "3":
            print(f"\n=== ç¨‹é›¶ä¹å½“å‰çŠ¶æ€ ===")
            
            # åŸºæœ¬ä¿¡æ¯
            basic_info = automation.pm.personality.get("basic_info", {})
            print(f"å§“å: {basic_info.get('name', 'ç¨‹é›¶ä¹')}")
            print(f"èŒä¸š: {basic_info.get('job', 'å¤–æ˜Ÿæ”¿åºœæ–‡åŒ–ç ”ç©¶å‘˜')}")
            
            # å¿ƒç†å‘å±•çŠ¶æ€
            psych_summary = automation.pm.growth_manager.get_current_psychological_summary()
            print(f"\nã€å¿ƒç†å‘å±•çŠ¶æ€ã€‘")
            print(f"äººæ ¼æˆç†Ÿåº¦: {psych_summary.get('personality_maturity', 50):.1f}/100")
            print(f"æƒ…æ„Ÿæ™ºåŠ›: {psych_summary.get('emotional_intelligence', 50):.1f}/100")
            print(f"å¿ƒç†å¥åº·: {psych_summary.get('psychological_wellbeing', 'å‘å±•ä¸­')}")
            print(f"æˆé•¿è½¨è¿¹: {psych_summary.get('growth_trajectory', 'ç§¯æå‘å±•')}")
            print(f"æ–°ä½“éªŒå‡†å¤‡åº¦: {psych_summary.get('readiness_for_new_experiences', 50):.1f}/100")
            
            # å¤§äº”äººæ ¼ç‰¹è´¨
            big_five = automation.pm.personality.get("psychological_profile", {}).get("big_five_personality", {})
            if big_five:
                print(f"\nã€å¤§äº”äººæ ¼ç‰¹è´¨ã€‘")
                print(f"å¼€æ”¾æ€§: {big_five.get('openness', 50):.1f}/100")
                print(f"å°½è´£æ€§: {big_five.get('conscientiousness', 50):.1f}/100") 
                print(f"å¤–å‘æ€§: {big_five.get('extraversion', 50):.1f}/100")
                print(f"å®œäººæ€§: {big_five.get('agreeableness', 50):.1f}/100")
                print(f"ç¥ç»è´¨: {big_five.get('neuroticism', 50):.1f}/100")
            
            # æƒ…æ„Ÿæ™ºåŠ›
            ei = automation.pm.personality.get("psychological_profile", {}).get("emotional_intelligence", {})
            if ei:
                print(f"\nã€æƒ…æ„Ÿæ™ºåŠ›å‘å±•ã€‘")
                print(f"è‡ªæˆ‘è§‰å¯Ÿ: {ei.get('self_awareness', 50):.1f}/100")
                print(f"è‡ªæˆ‘è°ƒèŠ‚: {ei.get('self_regulation', 50):.1f}/100")
                print(f"ç¤¾ä¼šè§‰å¯Ÿ: {ei.get('social_awareness', 50):.1f}/100")
                print(f"å…³ç³»ç®¡ç†: {ei.get('relationship_management', 50):.1f}/100")
                print(f"æˆé•¿é˜¶æ®µ: {ei.get('emotional_growth_stage', 'æœªçŸ¥')}")
            
            # å­¦ä¹ è¿›åº¦
            learning = automation.pm.personality.get("learning_progress", {})
            print(f"\nã€å­¦ä¹ æ´»åŠ¨ç»Ÿè®¡ã€‘")
            print(f"æ€»å­¦ä¹ å¤©æ•°: {learning.get('total_days', 0)}")
            print(f"æœ€åå­¦ä¹ æ—¥æœŸ: {learning.get('last_study_date', 'æœªçŸ¥')}")
            print(f"æ”¶é›†æ–°é—»æ¬¡æ•°: {len(automation.pm.knowledge['daily_news'])}")
            print(f"å‘å¸ƒæ¬¡æ•°: {len(automation.pm.posts['history'])}")
            print(f"åˆ†æè®°å½•: {len(automation.pm.memories['daily_analysis'])}")
            
            # å¿ƒç†æˆé•¿é‡Œç¨‹ç¢‘
            milestones = learning.get("psychological_milestones", [])
            if milestones:
                print(f"\nã€å¿ƒç†æˆé•¿é‡Œç¨‹ç¢‘ã€‘")
                for i, milestone in enumerate(milestones[-3:], 1):  # æ˜¾ç¤ºæœ€è¿‘3ä¸ª
                    print(f"{i}. {milestone}")
                    
            print(f"\nç¨‹é›¶ä¹æ­£åœ¨æŒç»­æˆé•¿ä¸­... ğŸŒ±")
        elif choice == "4":
            automation.run_daily_cycle()
            await automation.run_post_cycle()
        elif choice == "5":
            if await automation.poster.test_connection():
                print("MCPè¿æ¥æ­£å¸¸")
            else:
                print("MCPè¿æ¥å¤±è´¥")
        elif choice == "6":
            print("å†è§ï¼111 110110000101111 111")
            break
        else:
            print("æ— æ•ˆé€‰æ‹©!")

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--manual":
        # æ‰‹åŠ¨æ¨¡å¼
        asyncio.run(manual_mode())
    elif len(sys.argv) > 1 and sys.argv[1] == "--daemon":
        # å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼
        automation = XiaohongshuAutomation()
        setup_schedule(automation)
        
        logging.info("ç¨‹é›¶ä¹çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿå¯åŠ¨ä¸­...")
        logging.info("ç­‰å¾…å®šæ—¶ä»»åŠ¡æ‰§è¡Œ...")
        
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    else:
        # é»˜è®¤è¿è¡Œä¸€æ¬¡å®Œæ•´å¾ªç¯
        automation = XiaohongshuAutomation()
        
        # å…ˆæ”¶é›†æ–°é—»
        automation.run_daily_cycle()
        
        # ç„¶åå‘å¸ƒå†…å®¹
        asyncio.run(automation.run_post_cycle())

if __name__ == "__main__":
    print("ç¨‹é›¶ä¹çš„å°çº¢ä¹¦AIè‡ªåŠ¨åŒ–ç³»ç»Ÿ")
    print("å¤–æ˜Ÿæ”¿åºœå·¥ä½œå¥³å­©çš„åœ°çƒå­¦ä¹ ä¹‹æ—…")
    print()
    
    try:
        main()
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º! 111 110110000101111")
    except Exception as e:
        logging.error(f"ç¨‹åºå¼‚å¸¸: {e}")
        print(f"\nç¨‹åºå¼‚å¸¸: {e}")